{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50fa6ff1-94f3-40c3-a961-037c4e7084eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time, json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851cb2e8-5295-43ae-b9aa-f2332cf7a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_PATH = Path(\"/Users/clockorangezoe/Documents/phd_projects/code/geoAI/RDProLLMagent/doc/RDPro.md\")\n",
    "PY_PATH  = Path(\"/Users/clockorangezoe/Documents/phd_projects/code/geoAI/RDProLLMagent/python/ndvi.py\")\n",
    "assert DOC_PATH.exists(), f\"Missing: {DOC_PATH}\"\n",
    "assert PY_PATH.exists(), f\"Missing: {PY_PATH}\"\n",
    "\n",
    "rdpro_text = DOC_PATH.read_text(encoding=\"utf-8\")\n",
    "py_code = PY_PATH.read_text(encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3a1513-bb10-404c-bc34-48a62d38b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    chunk_id: str\n",
    "    heading_path: str\n",
    "    level: int\n",
    "    text: str\n",
    "\n",
    "def chunk_markdown_by_headings(md: str) -> List[Chunk]:\n",
    "    lines = md.splitlines()\n",
    "    starts = []\n",
    "    for i, line in enumerate(lines):\n",
    "        m = re.match(r\"^(#{2,3})\\s+(.*\\S)\\s*$\", line)\n",
    "        if m:\n",
    "            starts.append((i, len(m.group(1)), m.group(2).strip()))\n",
    "\n",
    "    if not starts:\n",
    "        return [Chunk(\"c0000\", \"DOC\", 1, md.strip() + \"\\n\")]\n",
    "\n",
    "    chunks: List[Chunk] = []\n",
    "    current_h2: Optional[str] = None\n",
    "\n",
    "    for idx, (start_i, level, title) in enumerate(starts):\n",
    "        end_i = starts[idx + 1][0] if idx + 1 < len(starts) else len(lines)\n",
    "        body = \"\\n\".join(lines[start_i:end_i]).strip() + \"\\n\"\n",
    "\n",
    "        if level == 2:\n",
    "            current_h2 = title\n",
    "            heading_path = current_h2\n",
    "        else:\n",
    "            heading_path = f\"{current_h2} / {title}\" if current_h2 else title\n",
    "\n",
    "        chunks.append(Chunk(f\"c{idx:04d}\", heading_path, level, body))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def select_chunks_manual(chunks: List[Chunk], include_keywords: List[str]) -> List[Chunk]:\n",
    "    inc = [k.lower() for k in include_keywords]\n",
    "    selected: List[Chunk] = []\n",
    "    for ch in chunks:\n",
    "        hay = (ch.heading_path + \"\\n\" + ch.text).lower()\n",
    "        if any(k in hay for k in inc):\n",
    "            selected.append(ch)\n",
    "\n",
    "    # de-dupe (preserve order)\n",
    "    seen = set()\n",
    "    uniq: List[Chunk] = []\n",
    "    for ch in selected:\n",
    "        if ch.chunk_id not in seen:\n",
    "            uniq.append(ch)\n",
    "            seen.add(ch.chunk_id)\n",
    "    return uniq\n",
    "\n",
    "def select_chunks_manual_api_keys(chunks: List[Chunk], api_keys: List[str]) -> List[Chunk]:\n",
    "    \"\"\"\n",
    "    Strict manual selection: only select chunks that contain at least one explicit API key.\n",
    "    This prevents pulling unrelated chunks like Flatten/Explode/Reshape unless you include them.\n",
    "    \"\"\"\n",
    "    keys = [k.lower() for k in api_keys]\n",
    "\n",
    "    selected: List[Chunk] = []\n",
    "    for ch in chunks:\n",
    "        hay = (ch.heading_path + \"\\n\" + ch.text).lower()\n",
    "        if any(key in hay for key in keys):\n",
    "            selected.append(ch)\n",
    "\n",
    "    # de-dupe (preserve order)\n",
    "    seen = set()\n",
    "    uniq: List[Chunk] = []\n",
    "    for ch in selected:\n",
    "        if ch.chunk_id not in seen:\n",
    "            uniq.append(ch)\n",
    "            seen.add(ch.chunk_id)\n",
    "    return uniq\n",
    "\n",
    "def make_doc_pack(selected: List[Chunk]) -> str:\n",
    "    out = []\n",
    "    for ch in selected:\n",
    "        out.append(f\"### DOC CHUNK {ch.chunk_id}: {ch.heading_path}\\n{ch.text}\\n\")\n",
    "    return \"\\n\".join(out).strip() + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad98cf0b-627c-412c-96b8-08cc6583ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-5\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a geospatial data engineer and Spark systems expert.\n",
    "\n",
    "Convert a given geospatial Python script into Scala code that runs on RDPro (Spark-based raster processing).\n",
    "\n",
    "Hard rules:\n",
    "1) Output MUST be valid Scala.\n",
    "2) Use ONLY APIs that appear in the provided DOC CHUNKS.\n",
    "3) Do NOT invent APIs or overloads. If a method signature is not shown in DOC CHUNKS, do not guess.\n",
    "4) Preserve semantics (raster IO, pixel math, focal ops, projection/rescale if present).\n",
    "5) Assume large-scale distributed Spark execution.\n",
    "6) For lambdas passed to raster functions (e.g., mapPixels), add explicit parameter types when needed to compile.\n",
    "\n",
    "Output format:\n",
    "- First: Scala file content only (no markdown fences).\n",
    "- After the Scala: a short NOTES section listing:\n",
    "  (a) RDPro APIs used (names only)\n",
    "  (b) Unsupported operations and why\n",
    "  (c) Any assumptions about IO paths / bands / nodata\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ce21d5-6f33-47f5-97ff-e185d7537fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_prompt(doc_pack: str, py_code: str) -> str:\n",
    "    return f\"\"\"\n",
    "RDPro documentation (relevant DOC CHUNKS only):\n",
    "{doc_pack}\n",
    "\n",
    "Python script:\n",
    "{py_code}\n",
    "\n",
    "Task:\n",
    "Translate the Python script into Scala targeting RDPro on Spark.\n",
    "Use ONLY APIs described in the DOC CHUNKS.\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49fd3f1-8ae0-4584-8024-9560fa1ad238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 â€” LLM call stub (you plug in your model call here)\n",
    "def call_llm(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace this with your real LLM call.\n",
    "    It should return Scala code as a string.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Plug in your LLM API call here.\")\n",
    "\n",
    "# Example usage:\n",
    "# scala_code_manual = call_llm(prompt_manual)\n",
    "# scala_code_auto   = call_llm(prompt_auto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b25db4fb-49db-4c4c-9d46-95306e5c4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- MANUAL KEYWORDS (edit this list) ----\n",
    "NDVI_KEYS = [\n",
    "    \"setup\",\n",
    "    \"geoTiff\",\n",
    "    \"rastermetadata\",\n",
    "    \"overlay\",          # stack red + nir\n",
    "    \"mapPixels\",        # compute NDVI\n",
    "    \"saveAsGeoTiff\",    # write output\n",
    "    \"GeoTiffWriter\",    # compression + write options\n",
    "    \"Compression\",      # (optional) forces pulling compression option lines\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbf4a597-d0ce-48ac-8f85-1b6ff6187055",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_markdown_by_headings(rdpro_text)\n",
    "manual_selected = select_chunks_manual_api_keys(chunks, NDVI_KEYS)\n",
    "doc_pack = make_doc_pack(manual_selected)\n",
    "user_prompt = build_user_prompt(doc_pack, py_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ac8b2f3-4f8d-47e8-a161-88eae95867e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual chunks: 14\n",
      "Prompt chars: 18941\n",
      "Saved: runs/manual_oracle/prompt_manual.txt\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = Path(\"./runs/manual_oracle\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "(OUT_DIR / \"prompt_manual.txt\").write_text(user_prompt, encoding=\"utf-8\")\n",
    "(OUT_DIR / \"doc_selection.json\").write_text(\n",
    "    json.dumps([{\"id\": c.chunk_id, \"heading\": c.heading_path} for c in manual_selected], indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"Manual chunks:\", len(manual_selected))\n",
    "print(\"Prompt chars:\", len(user_prompt))\n",
    "print(\"Saved:\", OUT_DIR / \"prompt_manual.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a89cecf1-8c42-4543-bc7e-805a60152ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual chunks: 11\n",
      "Prompt chars: 15804\n",
      "Saved: runs/manual_oracle/prompt_manual.txt\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = Path(\"./runs/manual_oracle\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "(OUT_DIR / \"prompt_manual.txt\").write_text(user_prompt, encoding=\"utf-8\")\n",
    "(OUT_DIR / \"doc_selection.json\").write_text(\n",
    "    json.dumps([{\"id\": c.chunk_id, \"heading\": c.heading_path} for c in manual_selected], indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"Manual chunks:\", len(manual_selected))\n",
    "print(\"Prompt chars:\", len(user_prompt))\n",
    "print(\"Saved:\", OUT_DIR / \"prompt_manual.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2de4573b-87e7-4e05-8a1f-3d0ef6913852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if \"OPENAI_API_KEY\" in os.environ:\n",
    "    print(\"OPENAI_API_KEY is set\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY is NOT set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc3d69f0-fded-4d09-85bd-642f9369fdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: runs/manual_oracle/Job.manual.scala\n",
      "LLM latency: 145.12 s\n",
      "\n",
      "--- Preview ---\n",
      " import org.apache.spark.{SparkConf, SparkContext}\n",
      "\n",
      "object ComputeNDVI {\n",
      "  def main(args: Array[String]): Unit = {\n",
      "    val B4_PATH: String =\n",
      "      if (args.length >= 1) args(0)\n",
      "      else \"/content/B4/LC09_L2SP_040036_20250803_20250804_02_T1_SR_B4.TIF\"\n",
      "    val B5_PATH: String =\n",
      "      if (args.length >= 2) args(1)\n",
      "      else \"/content/B5/LC09_L2SP_040036_20250803_20250804_02_T1_SR_B5.TIF\"\n",
      "    val OUT_NDVI: String =\n",
      "      if (args.length >= 3) args(2)\n",
      "      else \"/content/ndvi.tif\"\n",
      "\n",
      "    val conf = new SparkConf().setAppName(\"ComputeNDVI\")\n",
      "    val sc = new SparkContext(conf)\n",
      "\n",
      "    // Load single-band rasters as Float\n",
      "    val red: RasterRDD[Float] = sc.geoTiff[Float](B4_PATH)\n",
      "    val nir: RasterRDD[Float] = sc.geoTiff[Float](B5_PATH)\n",
      "\n",
      "    // Check grid alignment by comparing RasterMetadata\n",
      "    val redMD: RasterMetadata = red.flatten.first._3\n",
      "    val nirMD: RasterMetadata = nir.flatten.first._3\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def run_llm(prompt: str) -> Tuple[str, float]:\n",
    "    t0 = time.time()\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    return resp.output_text.strip(), time.time() - t0\n",
    "\n",
    "scala_out, dt = run_llm(user_prompt)\n",
    "(OUT_DIR / \"Job.manual.scala\").write_text(scala_out, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Wrote:\", OUT_DIR / \"Job.manual.scala\")\n",
    "print(\"LLM latency:\", round(dt, 2), \"s\")\n",
    "print(\"\\n--- Preview ---\\n\", scala_out[:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc60da-ca53-4071-bd13-b3b82e53fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
