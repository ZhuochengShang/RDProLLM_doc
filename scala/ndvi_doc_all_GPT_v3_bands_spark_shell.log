SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/Users/clockorangezoe/Documents/EnvUtilities/spark-3.3.1-bin-hadoop3/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/clockorangezoe/Documents/EnvUtilities/hadoop-3.2.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
26/02/10 23:44:09 WARN Utils: Your hostname, Clockoranges-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.68.60 instead (on interface en0)
26/02/10 23:44:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
https://repo.osgeo.org/repository/geotools-releases/ added as a remote repository with the name: repo-1
https://repo.osgeo.org/repository/release/ added as a remote repository with the name: repo-2
:: loading settings :: url = jar:file:/Users/clockorangezoe/Documents/EnvUtilities/spark-3.3.1-bin-hadoop3/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /Users/clockorangezoe/Documents/phd_projects/code/geoAI/RDProLLM_doc/notebook/runs/ndvi_eval/.ivy2/cache
The jars for the packages stored in: /Users/clockorangezoe/Documents/phd_projects/code/geoAI/RDProLLM_doc/notebook/runs/ndvi_eval/.ivy2/jars
org.locationtech.jts#jts-core added as a dependency
org.geotools#gt-referencing added as a dependency
org.geotools#gt-epsg-hsql added as a dependency
org.geotools#gt-geotiff added as a dependency
org.geotools#gt-coverage added as a dependency
it.geosolutions.imageio-ext#imageio-ext-tiff added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-df6d96f5-e592-4382-961b-c2a9530278c7;1.0
	confs: [default]
	found org.locationtech.jts#jts-core;1.19.0 in local-m2-cache
	found org.geotools#gt-referencing;24.1 in repo-1
	found org.ejml#ejml-ddense;0.34 in local-m2-cache
	found org.ejml#ejml-core;0.34 in local-m2-cache
	found commons-pool#commons-pool;1.5.4 in local-m2-cache
	found org.geotools#gt-metadata;24.1 in repo-1
	found org.geotools#gt-opengis;24.1 in repo-1
	found systems.uom#systems-common;2.0.1 in central
	found javax.measure#unit-api;2.0 in local-m2-cache
	found tech.units#indriya;2.0.2 in local-m2-cache
	found tech.uom.lib#uom-lib-common;2.0 in local-m2-cache
	found javax.inject#javax.inject;1 in local-m2-cache
	found si.uom#si-quantity;2.0.1 in local-m2-cache
	found si.uom#si-units;2.0.1 in local-m2-cache
	found jakarta.annotation#jakarta.annotation-api;1.3.4 in local-m2-cache
	found javax.media#jai_core;1.1.3 in local-m2-cache
	found org.apache.commons#commons-lang3;3.8.1 in local-m2-cache
	found org.geotools.ogc#net.opengis.ows;24.1 in repo-1
	found org.geotools.ogc#org.w3.xlink;24.1 in repo-1
	found org.eclipse.emf#org.eclipse.emf.common;2.15.0 in local-m2-cache
	found org.eclipse.emf#org.eclipse.emf.ecore;2.15.0 in local-m2-cache
	found org.eclipse.emf#org.eclipse.emf.ecore.xmi;2.15.0 in local-m2-cache
	found it.geosolutions.jgridshift#jgridshift-core;1.3 in local-m2-cache
	found net.sf.geographiclib#GeographicLib-Java;1.49 in local-m2-cache
	found org.geotools#gt-epsg-hsql;24.1 in repo-1
	found org.hsqldb#hsqldb;2.4.1 in local-m2-cache
	found org.geotools#gt-geotiff;24.1 in repo-1
	found org.geotools#gt-main;24.1 in repo-1
	found org.apache.commons#commons-text;1.6 in local-m2-cache
	found com.fasterxml.jackson.core#jackson-core;2.10.1 in central
	found org.geotools#gt-coverage;24.1 in repo-1
	found javax.media#jai_imageio;1.1 in local-m2-cache
	found org.jaitools#jt-zonalstats;1.6.0 in local-m2-cache
	found org.jaitools#jt-utils;1.6.0 in local-m2-cache
	found it.geosolutions.jaiext.affine#jt-affine;1.1.17 in repo-2
	found it.geosolutions.jaiext.iterators#jt-iterators;1.1.17 in repo-2
	found javax.media#jai_codec;1.1.3 in local-m2-cache
	found it.geosolutions.jaiext.utilities#jt-utilities;1.1.17 in repo-2
	found it.geosolutions.jaiext.scale#jt-scale;1.1.17 in repo-2
	found it.geosolutions.jaiext.vectorbin#jt-vectorbin;1.1.17 in repo-2
	found it.geosolutions.jaiext.translate#jt-translate;1.1.17 in repo-2
	found it.geosolutions.jaiext.algebra#jt-algebra;1.1.17 in repo-2
	found it.geosolutions.jaiext.bandmerge#jt-bandmerge;1.1.17 in repo-2
	found it.geosolutions.jaiext.bandselect#jt-bandselect;1.1.17 in repo-2
	found it.geosolutions.jaiext.bandcombine#jt-bandcombine;1.1.17 in repo-2
	found it.geosolutions.jaiext.border#jt-border;1.1.17 in repo-2
	found it.geosolutions.jaiext.buffer#jt-buffer;1.1.17 in repo-2
	found it.geosolutions.jaiext.crop#jt-crop;1.1.17 in repo-2
	found it.geosolutions.jaiext.mosaic#jt-mosaic;1.1.17 in repo-2
	found it.geosolutions.jaiext.lookup#jt-lookup;1.1.17 in repo-2
	found it.geosolutions.jaiext.nullop#jt-nullop;1.1.17 in repo-2
	found it.geosolutions.jaiext.rescale#jt-rescale;1.1.17 in repo-2
	found it.geosolutions.jaiext.scale2#jt-scale2;1.1.17 in repo-2
	found org.huldra.math#bigint;0.7.1 in local-m2-cache
	found it.geosolutions.jaiext.stats#jt-stats;1.1.17 in repo-2
	found com.google.guava#guava;25.1-jre in central
	found com.google.code.findbugs#jsr305;3.0.2 in local-m2-cache
	found org.checkerframework#checker-qual;2.0.0 in central
	found com.google.errorprone#error_prone_annotations;2.1.3 in central
	found com.google.j2objc#j2objc-annotations;1.1 in local-m2-cache
	found org.codehaus.mojo#animal-sniffer-annotations;1.14 in central
	found it.geosolutions.jaiext.warp#jt-warp;1.1.17 in repo-2
	found it.geosolutions.jaiext.zonal#jt-zonal;1.1.17 in repo-2
	found it.geosolutions.jaiext.binarize#jt-binarize;1.1.17 in repo-2
	found it.geosolutions.jaiext.format#jt-format;1.1.17 in repo-2
	found it.geosolutions.jaiext.colorconvert#jt-colorconvert;1.1.17 in repo-2
	found it.geosolutions.jaiext.errordiffusion#jt-errordiffusion;1.1.17 in repo-2
	found it.geosolutions.jaiext.orderdither#jt-orderdither;1.1.17 in repo-2
	found it.geosolutions.jaiext.colorindexer#jt-colorindexer;1.1.17 in repo-2
	found it.geosolutions.jaiext.imagefunction#jt-imagefunction;1.1.17 in repo-2
	found it.geosolutions.jaiext.piecewise#jt-piecewise;1.1.17 in repo-2
	found it.geosolutions.jaiext.classifier#jt-classifier;1.1.17 in repo-2
	found it.geosolutions.jaiext.rlookup#jt-rlookup;1.1.17 in repo-2
	found it.geosolutions.jaiext.shadedrelief#jt-shadedrelief;1.1.17 in repo-2
	found commons-io#commons-io;2.6 in local-m2-cache
	found it.geosolutions.imageio-ext#imageio-ext-tiff;1.4.14 in repo-2
	found it.geosolutions.imageio-ext#imageio-ext-utilities;1.4.14 in repo-2
	found it.geosolutions.imageio-ext#imageio-ext-geocore;1.4.14 in repo-2
	found it.geosolutions.imageio-ext#imageio-ext-streams;1.4.14 in repo-2
	found javax.xml.bind#jaxb-api;2.4.0-b180830.0359 in local-m2-cache
	found javax.activation#javax.activation-api;1.2.0 in local-m2-cache
	found org.glassfish.jaxb#jaxb-runtime;2.4.0-b180830.0438 in local-m2-cache
	found org.glassfish.jaxb#txw2;2.4.0-b180830.0438 in local-m2-cache
	found com.sun.istack#istack-commons-runtime;3.0.7 in local-m2-cache
	found org.jvnet.staxex#stax-ex;1.8 in local-m2-cache
	found com.sun.xml.fastinfoset#FastInfoset;1.2.15 in local-m2-cache
	found io.airlift#aircompressor;0.27 in local-m2-cache
:: resolution report :: resolve 859ms :: artifacts dl 15ms
	:: modules in use:
	com.fasterxml.jackson.core#jackson-core;2.10.1 from central in [default]
	com.google.code.findbugs#jsr305;3.0.2 from local-m2-cache in [default]
	com.google.errorprone#error_prone_annotations;2.1.3 from central in [default]
	com.google.guava#guava;25.1-jre from central in [default]
	com.google.j2objc#j2objc-annotations;1.1 from local-m2-cache in [default]
	com.sun.istack#istack-commons-runtime;3.0.7 from local-m2-cache in [default]
	com.sun.xml.fastinfoset#FastInfoset;1.2.15 from local-m2-cache in [default]
	commons-io#commons-io;2.6 from local-m2-cache in [default]
	commons-pool#commons-pool;1.5.4 from local-m2-cache in [default]
	io.airlift#aircompressor;0.27 from local-m2-cache in [default]
	it.geosolutions.imageio-ext#imageio-ext-geocore;1.4.14 from repo-2 in [default]
	it.geosolutions.imageio-ext#imageio-ext-streams;1.4.14 from repo-2 in [default]
	it.geosolutions.imageio-ext#imageio-ext-tiff;1.4.14 from repo-2 in [default]
	it.geosolutions.imageio-ext#imageio-ext-utilities;1.4.14 from repo-2 in [default]
	it.geosolutions.jaiext.affine#jt-affine;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.algebra#jt-algebra;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.bandcombine#jt-bandcombine;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.bandmerge#jt-bandmerge;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.bandselect#jt-bandselect;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.binarize#jt-binarize;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.border#jt-border;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.buffer#jt-buffer;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.classifier#jt-classifier;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.colorconvert#jt-colorconvert;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.colorindexer#jt-colorindexer;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.crop#jt-crop;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.errordiffusion#jt-errordiffusion;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.format#jt-format;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.imagefunction#jt-imagefunction;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.iterators#jt-iterators;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.lookup#jt-lookup;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.mosaic#jt-mosaic;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.nullop#jt-nullop;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.orderdither#jt-orderdither;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.piecewise#jt-piecewise;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.rescale#jt-rescale;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.rlookup#jt-rlookup;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.scale#jt-scale;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.scale2#jt-scale2;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.shadedrelief#jt-shadedrelief;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.stats#jt-stats;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.translate#jt-translate;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.utilities#jt-utilities;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.vectorbin#jt-vectorbin;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.warp#jt-warp;1.1.17 from repo-2 in [default]
	it.geosolutions.jaiext.zonal#jt-zonal;1.1.17 from repo-2 in [default]
	it.geosolutions.jgridshift#jgridshift-core;1.3 from local-m2-cache in [default]
	jakarta.annotation#jakarta.annotation-api;1.3.4 from local-m2-cache in [default]
	javax.activation#javax.activation-api;1.2.0 from local-m2-cache in [default]
	javax.inject#javax.inject;1 from local-m2-cache in [default]
	javax.measure#unit-api;2.0 from local-m2-cache in [default]
	javax.media#jai_codec;1.1.3 from local-m2-cache in [default]
	javax.media#jai_core;1.1.3 from local-m2-cache in [default]
	javax.media#jai_imageio;1.1 from local-m2-cache in [default]
	javax.xml.bind#jaxb-api;2.4.0-b180830.0359 from local-m2-cache in [default]
	net.sf.geographiclib#GeographicLib-Java;1.49 from local-m2-cache in [default]
	org.apache.commons#commons-lang3;3.8.1 from local-m2-cache in [default]
	org.apache.commons#commons-text;1.6 from local-m2-cache in [default]
	org.checkerframework#checker-qual;2.0.0 from central in [default]
	org.codehaus.mojo#animal-sniffer-annotations;1.14 from central in [default]
	org.eclipse.emf#org.eclipse.emf.common;2.15.0 from local-m2-cache in [default]
	org.eclipse.emf#org.eclipse.emf.ecore;2.15.0 from local-m2-cache in [default]
	org.eclipse.emf#org.eclipse.emf.ecore.xmi;2.15.0 from local-m2-cache in [default]
	org.ejml#ejml-core;0.34 from local-m2-cache in [default]
	org.ejml#ejml-ddense;0.34 from local-m2-cache in [default]
	org.geotools#gt-coverage;24.1 from repo-1 in [default]
	org.geotools#gt-epsg-hsql;24.1 from repo-1 in [default]
	org.geotools#gt-geotiff;24.1 from repo-1 in [default]
	org.geotools#gt-main;24.1 from repo-1 in [default]
	org.geotools#gt-metadata;24.1 from repo-1 in [default]
	org.geotools#gt-opengis;24.1 from repo-1 in [default]
	org.geotools#gt-referencing;24.1 from repo-1 in [default]
	org.geotools.ogc#net.opengis.ows;24.1 from repo-1 in [default]
	org.geotools.ogc#org.w3.xlink;24.1 from repo-1 in [default]
	org.glassfish.jaxb#jaxb-runtime;2.4.0-b180830.0438 from local-m2-cache in [default]
	org.glassfish.jaxb#txw2;2.4.0-b180830.0438 from local-m2-cache in [default]
	org.hsqldb#hsqldb;2.4.1 from local-m2-cache in [default]
	org.huldra.math#bigint;0.7.1 from local-m2-cache in [default]
	org.jaitools#jt-utils;1.6.0 from local-m2-cache in [default]
	org.jaitools#jt-zonalstats;1.6.0 from local-m2-cache in [default]
	org.jvnet.staxex#stax-ex;1.8 from local-m2-cache in [default]
	org.locationtech.jts#jts-core;1.19.0 from local-m2-cache in [default]
	si.uom#si-quantity;2.0.1 from local-m2-cache in [default]
	si.uom#si-units;2.0.1 from local-m2-cache in [default]
	systems.uom#systems-common;2.0.1 from central in [default]
	tech.units#indriya;2.0.2 from local-m2-cache in [default]
	tech.uom.lib#uom-lib-common;2.0 from local-m2-cache in [default]
	:: evicted modules:
	org.locationtech.jts#jts-core;1.17.1 by [org.locationtech.jts#jts-core;1.19.0] in [default]
	it.geosolutions.imageio-ext#imageio-ext-tiff;1.3.2 by [it.geosolutions.imageio-ext#imageio-ext-tiff;1.4.14] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   89  |   0   |   0   |   2   ||   87  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-df6d96f5-e592-4382-961b-c2a9530278c7
	confs: [default]
	0 artifacts copied, 87 already retrieved (0kB/16ms)
26/02/10 23:44:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://192.168.68.60:4040
Spark context available as 'sc' (master = local[*], app id = local-1770795854726).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.3.1
      /_/
         
Using Scala version 2.12.15 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_381)
Type in expressions to have them evaluated.
Type :help for more information.

scala> import edu.ucr.cs.bdlab.beast._
import edu.ucr.cs.bdlab.beast._

scala> import edu.ucr.cs.bdlab.raptor.GeoTiffWriter
import edu.ucr.cs.bdlab.raptor.GeoTiffWriter

scala> import edu.ucr.cs.bdlab.beast.io.tiff.TiffConstants
import edu.ucr.cs.bdlab.beast.io.tiff.TiffConstants

scala> import org.apache.spark.SparkContext
import org.apache.spark.SparkContext

scala> import org.apache.spark.sql.types.{ArrayType, FloatType, IntegerType}
import org.apache.spark.sql.types.{ArrayType, FloatType, IntegerType}

scala> 

scala> import java.net.URI
import java.net.URI

scala> import java.nio.file.Paths
import java.nio.file.Paths

scala> import org.apache.hadoop.fs.{FileSystem, Path}
import org.apache.hadoop.fs.{FileSystem, Path}

scala> 

scala> object NDVIFromAnalyticMS {
     |   // Indices are 0-based for RDPro Arrays (Planet AnalyticMS: Red=3, NIR= 
4 in GDAL 1-based)
     |   private val RedBandIndex0: Int = 2
     |   private val NirBandIndex0: Int = 3
     |   private val NdviNoData: Float = -9999.0f
     | 
     |   def run(sc: SparkContext): Unit = {
     |     // Safe defaults (from the provided Python)
     |     val defaultIn = "/Users/clockorangezoe/Desktop/PlanetAPI/example/2023 
0527_180231_61_247b_3B_AnalyticMS.tif"
     |     val defaultOut = "/Users/clockorangezoe/Documents/phd_projects/code/g 
eoAI/RDProLLM_doc/output/ndvi_band.v3.tif"
     | 
     |     // Try to read two args from SparkConf (optional), else use defaults
     |     // Expected: spark-submit ... --conf rdpro.args="<inputPath>|<outputP 
ath>"
     |     val argStr = sc.getConf.get("rdpro.args", s"$defaultIn|$defaultOut")
     |     val parts = argStr.split("\\|", -1).map(_.trim)
     |     val inPathRaw = parts.headOption.getOrElse(defaultIn)
     |     val outPathRaw = parts.lift(1).getOrElse(defaultOut)
     | 
     |     // Normalize I/O paths per environment rules
     |     val inputPath = normalizePath(sc, inPathRaw)
     |     val desiredOutPath = normalizePath(sc, outPathRaw)
     | 
     |     // Resolve final output path and ensure parent directory exists
     |     val (finalOutPathStr, fs) = prepareOutputPath(sc, desiredOutPath)
     | 
     |     // Probe pixel type to branch into the correct RDPro loader
     |     val probe = sc.geoTiff(inputPath)
     |     val pixelType = probe.first.pixelType
     | 
     |     pixelType match {
     |       case ArrayType(IntegerType, _) =>
     |         val mb: RasterRDD[Array[Int]] = sc.geoTiff[Array[Int]](inputPath) 
     |         val ndvi: RasterRDD[Float] = mb.mapPixels((bands: Array[Int]) =>  
{
     |           if (bands == null || bands.length <= NirBandIndex0 || bands.len 
gth <= RedBandIndex0)
     |             throw new RuntimeException(s"Raster does not contain required 
 bands: need at least index $NirBandIndex0 (0-based). Found length=${if (bands== 
null) 0 else bands.length}")
     |           val red: Float = bands(RedBandIndex0).toFloat
     |           val nir: Float = bands(NirBandIndex0).toFloat
     |           val denom: Float = nir + red
     |           if (denom == 0.0f) NdviNoData else (nir - red) / denom
     |         })
     |         // Write single-file GeoTIFF (compatibility) with LZW compression 
     |         ndvi.saveAsGeoTiff(finalOutPathStr,
     |           Seq(
     |             GeoTiffWriter.Compression -> TiffConstants.COMPRESSION_LZW,
     |             GeoTiffWriter.WriteMode -> "compatibility"
     |           )
     |         )
     | 
     |       case ArrayType(FloatType, _) =>
     |         val mb: RasterRDD[Array[Float]] = sc.geoTiff[Array[Float]](inputP 
ath)
     |         val ndvi: RasterRDD[Float] = mb.mapPixels((bands: Array[Float]) = 
> {
     |           if (bands == null || bands.length <= NirBandIndex0 || bands.len 
gth <= RedBandIndex0)
     |             throw new RuntimeException(s"Raster does not contain required 
 bands: need at least index $NirBandIndex0 (0-based). Found length=${if (bands== 
null) 0 else bands.length}")
     |           val red: Float = bands(RedBandIndex0)
     |           val nir: Float = bands(NirBandIndex0)
     |           if (java.lang.Float.isNaN(red) || java.lang.Float.isNaN(nir)) { 
     |             NdviNoData
     |           } else {
     |             val denom: Float = nir + red
     |             if (denom == 0.0f) NdviNoData else (nir - red) / denom
     |           }
     |         })
     |         // Write single-file GeoTIFF (compatibility) with LZW compression 
     |         ndvi.saveAsGeoTiff(finalOutPathStr,
     |           Seq(
     |             GeoTiffWriter.Compression -> TiffConstants.COMPRESSION_LZW,
     |             GeoTiffWriter.WriteMode -> "compatibility"
     |           )
     |         )
     | 
     |       case IntegerType | FloatType =>
     |         throw new IllegalArgumentException(
     |           s"Expected a multi-band raster (Array pixel type) to compute ND 
VI. Found scalar pixel type: $pixelType"
     |         )
     | 
     |       case other =>
     |         throw new IllegalArgumentException(s"Unsupported pixel type for t 
his operation: $other")
     |     }
     | 
     |     println(s"NDVI written to: $finalOutPathStr")
     |   }
     | 
     |   // ----------------- Helpers -----------------
     | 
     |   private def normalizePath(sc: SparkContext, path: String): String = {
     |     if (path == null || path.isEmpty) return path
     |     val isLocalMode: Boolean = Option(sc.master).exists(_.toLowerCase.sta 
rtsWith("local"))
     |     val uri = try new URI(path) catch { case _: Throwable => null }
     |     val hasScheme = uri != null && uri.getScheme != null
     | 
     |     if (hasScheme) {
     |       path
     |     } else {
     |       if (isLocalMode && looksLikeLocalAbsolute(path)) {
     |         Paths.get(path).toAbsolutePath.toUri.toString
     |       } else {
     |         // Leave scheme-less path unchanged to resolve against cluster fi 
lesystem
     |         path
     |       }
     |     }
     |   }
     | 
     |   private def looksLikeLocalAbsolute(p: String): Boolean = {
     |     if (p == null) return false
     |     val s = p.trim
     |     s.startsWith("/") || s.matches("^[a-zA-Z]:\\\\.*")
     |   }
     | 
     |   private def prepareOutputPath(sc: SparkContext, desiredOutPath: String) 
: (String, FileSystem) = {
     |     val outURI = new URI(desiredOutPath)
     |     val conf = sc.hadoopConfiguration
     |     val fs = FileSystem.get(outURI, conf)
     |     var outPath = new Path(outURI)
     | 
     |     // If a file already exists at the target path, append ".tif" to avoi 
d overwrite
     |     if (fs.exists(outPath) && fs.isFile(outPath)) {
     |       val parent = Option(outPath.getParent).getOrElse(new Path(new URI(o 
utURI.getScheme + ":///")))
     |       val name = outPath.getName
     |       outPath = new Path(parent, name + ".tif")
     |     }
     | 
     |     // Ensure parent directory exists
     |     val parent = Option(outPath.getParent).getOrElse(new Path(new URI(out 
URI.getScheme + ":///")))
     |     if (!fs.exists(parent)) {
     |       fs.mkdirs(parent)
     |     }
     | 
     |     (outPath.toString, fs)
     |   }
     | }
warning: one deprecation; for details, enable `:setting -deprecation' or `:replay -deprecation'
defined object NDVIFromAnalyticMS

scala> 

scala> // NOTES

scala> // - RDPro APIs used:

scala> //   geoTiff[T], mapPixels, saveAsGeoTiff

scala> // - Unsupported operations and why:

scala> //   - Per-band NoData read/write: DOC does not expose band-level NoData  
retrieval or setting on output.

scala> //     We approximate masking only for Float arrays by treating NaN as No 
Data and always guard against zero denominator.

scala> //     Output NoData value (-9999.0) is used in pixel values but cannot b 
e registered in GeoTIFF tags via DOC APIs.

scala> //   - Explicit band metadata (names/count) is not exposed in DOC; we ass 
ume 0-based band indexing within Array[T] and

scala> //     validate band count at execution time inside mapPixels.

scala> // - Assumptions about IO paths / bands / nodata / CRS / environment dete 
ction logic:

scala> //   - Input is a multi-band Planet AnalyticMS GeoTIFF where Red is band  
index 2 and NIR is index 3 (0-based).

scala> //   - If denominator (NIR+Red) is zero, NDVI is set to -9999.0f.

scala> //   - In local Spark mode, absolute paths without a scheme are promoted  
to file:/// URIs to avoid Hadoop misinterpretation.

scala> //   - For non-local Spark or scheme-less inputs, paths are left unchange 
d to resolve via fs.defaultFS.

scala> //   - Output uses GeoTiffWriter.WriteMode -> "compatibility" to produce  
a single GIS-compatible file,

scala> //     with LZW compression. Parent directory is created if missing; if a 
 file exists at target path,

scala> //     ".tif" is appended to avoid overwrite.

scala> 

scala> val _r = NDVIFromAnalyticMS.run(sc)

[Stage 0:>                                                          (0 + 1) / 1]

                                                                                
org.apache.spark.SparkException: Task not serializable
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:444)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:416)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:163)
  at org.apache.spark.SparkContext.clean(SparkContext.scala:2491)
  at org.apache.spark.rdd.RDD.$anonfun$map$1(RDD.scala:414)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)
  at org.apache.spark.rdd.RDD.map(RDD.scala:413)
  at edu.ucr.cs.bdlab.raptor.RasterOperationsLocal$.mapPixels(RasterOperationsLocal.scala:41)
  at edu.ucr.cs.bdlab.raptor.RaptorMixin$RaptorMixinOperations3.mapPixels(RaptorMixin.scala:129)
  at NDVIFromAnalyticMS$.run(<console>:65)
  ... 49 elided
Caused by: java.io.NotSerializableException: NDVIFromAnalyticMS$
Serialization stack:
	- object not serializable (class: NDVIFromAnalyticMS$, value: NDVIFromAnalyticMS$@7bf8b430)
	- element of array (index: 0)
	- array (class [Ljava.lang.Object;, size 1)
	- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;)
	- object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class NDVIFromAnalyticMS$, functionalInterfaceMethod=scala/Function1.apply:(Ljava/lang/Object;)Ljava/lang/Object;, implementation=invokeStatic NDVIFromAnalyticMS$.$anonfun$run$4$adapted:(LNDVIFromAnalyticMS$;[I)Ljava/lang/Object;, instantiatedMethodType=([I)Ljava/lang/Object;, numCaptured=1])
	- writeReplace data (class: java.lang.invoke.SerializedLambda)
	- object (class NDVIFromAnalyticMS$$$Lambda$2947/2003434760, NDVIFromAnalyticMS$$$Lambda$2947/2003434760@2664d94)
	- element of array (index: 0)
	- array (class [Ljava.lang.Object;, size 2)
	- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;)
	- object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class edu.ucr.cs.bdlab.raptor.RasterOperationsLocal$, functionalInterfaceMethod=scala/Function1.apply:(Ljava/lang/Object;)Ljava/lang/Object;, implementation=invokeStatic edu/ucr/cs/bdlab/raptor/RasterOperationsLocal$.$anonfun$mapPixels$1:(Lscala/Function1;Lscala/reflect/ClassTag;Ledu/ucr/cs/bdlab/beast/geolite/ITile;)Ledu/ucr/cs/bdlab/raptor/MapPixelsTile;, instantiatedMethodType=(Ledu/ucr/cs/bdlab/beast/geolite/ITile;)Ledu/ucr/cs/bdlab/raptor/MapPixelsTile;, numCaptured=2])
	- writeReplace data (class: java.lang.invoke.SerializedLambda)
	- object (class edu.ucr.cs.bdlab.raptor.RasterOperationsLocal$$$Lambda$2976/396547916, edu.ucr.cs.bdlab.raptor.RasterOperationsLocal$$$Lambda$2976/396547916@748fb661)
  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:41)
  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:49)
  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:441)
  ... 60 more

scala> println("__DONE__ object=NDVIFromAnalyticMS")
__DONE__ object=NDVIFromAnalyticMS

scala> System.exit(0)
